|拆分方式|核心逻辑|优势|劣势|适用场景|
|---|---|---|---|---|
|网络拆分|每个 GPU 处理网络的不同层，数据按层传递|可训练更大网络，单个 GPU 显存占用低|GPU 间同步频繁，数据传输量大（激活值、梯度），负载难匹配|框架 / 系统支持多 GPU 互联，且网络层结构适合拆分的特殊场景|
|层内拆分|拆分单一层的计算任务（如卷积层通道数、全连接层输出单元数）|显存线性扩展，支持更大网络|需大量同步 / 屏障操作，数据传输量可能超过网络拆分|GPU 显存极小（如早期 2GB 显存设备）的历史场景|
|数据拆分（数据并行）|所有 GPU 执行相同网络逻辑，仅拆分小批量数据|实现最简单，同步仅在小批量训练后进行，可适配任意模型|无法训练更大模型（单个 GPU 需存完整参数）|主流场景，只要 GPU 显存足够容纳单模型参数|