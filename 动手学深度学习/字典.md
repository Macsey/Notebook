

在之前讲解深度学习文件读写时，我们提到了用 “字典” 存多个张量，很多同学可能会疑惑：“这里的‘字典’和平时说的字典有啥关系？在代码里到底是干啥用的？” 今天就用最通俗的话，把 “字典” 的本质、用法和在深度学习中的作用讲透。

## 一、先搞懂：字典到底是个啥？（生活类比版）

你可以把代码里的 “字典”，理解成**现实中带 “标签” 的收纳盒**—— 每个盒子里装着一个东西（比如一个张量、一串数据），盒子外面贴个标签，想找东西时不用翻遍所有盒子，直接按标签拿就行。

举个生活例子：

你有一个抽屉，里面放了 3 样东西：身份证、银行卡、校园卡。如果随便堆着，找身份证时得挨个翻；但如果给每样东西套一个 “标签袋”——“身份证袋” 装身份证、“银行卡袋” 装银行卡、“校园卡袋” 装校园卡，下次要找银行卡，直接抓 “银行卡袋” 就行。

代码里的 “字典”，就是这个 “带标签的收纳盒”：

- **标签**：在字典里叫 “键（key）”，必须是唯一的（就像不能有两个 “身份证袋” 标签）；

- **东西**：在字典里叫 “值（value）”，可以是任何数据（张量、数字、字符串都能装）；

- 整体关系：一个 “键” 对应一个 “值”，就像一个标签对应一个盒子里的东西，这种对应关系叫 “键值对”。

## 二、代码里的字典：怎么创建、怎么用？（实战入门）

在 Python（深度学习常用语言）里，字典的写法很简单：用大括号{}包裹，里面写 “键：值”，多个键值对用逗号隔开。我们结合之前的张量例子，一步步看怎么用。

### 1. 第一步：创建一个字典（搭好收纳盒）

比如我们要存两个张量：一个是 “训练数据的特征”（x），一个是 “训练数据的标签”（y），用字典给它们贴标签：

```python
import torch

# 先创建两个张量（要装的“东西”）

x = torch.arange(4) # 特征张量：[0,1,2,3]

y = torch.zeros(4) # 标签张量：[0,0,0,0]

# 创建字典：给每个张量贴“标签”（键值对）

tensor_dict = {

"train_features": x, # 键："train_features"（训练特征），值：x张量

"train_labels": y # 键："train_labels"（训练标签），值：y张量

}

# 打印字典看看效果

print(tensor_dict)

# 输出结果：

# {'train_features': tensor([0, 1, 2, 3]), 'train_labels': tensor([0., 0., 0., 0.])}
```

可以看到，字典清晰地把 “标签” 和 “张量” 对应起来了，一眼就知道每个张量是干啥的。

### 2. 第二步：用字典 —— 按 “标签” 找东西（查值）

如果想单独拿出 “训练特征” 的张量，不用像列表那样记位置（比如列表里 x 在第 0 位），直接用 “键”（标签）查就行，就像按 “身份证袋” 找身份证：

```python
# 按“键”找“值”：要“train_features”对应的张量

features = tensor_dict["train_features"]

print(features) # 输出：tensor([0, 1, 2, 3])

# 同样，找“train_labels”对应的张量

labels = tensor_dict["train_labels"]

print(labels) # 输出：tensor([0., 0., 0., 0.])
```

这比列表更灵活 —— 如果以后加了新的张量（比如 “测试数据”），只要加个新键值对，找的时候还是按标签查，不用管顺序。

### 3. 第三步：改字典 —— 给 “标签” 换东西（改值）

如果训练数据更新了，想把 “train_features” 对应的张量换成新的，直接用 “键” 修改就行，不用动其他部分：

```python
# 新的特征张量

new_x = torch.arange(5, 9) # [5,6,7,8]

# 用原来的键“train_features”替换值

tensor_dict["train_features"] = new_x

# 再查“train_features”，已经是新的了

print(tensor_dict["train_features"]) # 输出：tensor([5, 6, 7, 8])
```

## 三、深度学习里为啥非要用字典？（核心作用）

在之前的文件读写中，我们说 “用字典存多个张量方便”，到底方便在哪？结合实际场景看三个核心作用：

### 1. 存张量：给数据 “贴标签”，避免混乱

比如训练一个图像识别模型，我们需要存 4 个张量：训练特征、训练标签、测试特征、测试标签。如果用列表存，顺序错了就全乱了（比如把测试标签当成训练标签）；但用字典存，每个张量都有明确标签，永远不会搞混：

```python
# 用字典存4个张量，标签清晰

data_dict = {

"train_x": train_features, # 训练特征

"train_y": train_labels, # 训练标签

"test_x": test_features, # 测试特征

"test_y": test_labels # 测试标签

}

# 存到文件里

torch.save(data_dict, "data_dict.pth")

# 下次读的时候，按标签取，不用记顺序

loaded_dict = torch.load("data_dict.pth")

train_x = loaded_dict["train_x"] # 直接拿训练特征，不会错
```

### 2. 存模型参数：对应到每一层，方便管理

模型的参数（比如权重、偏置）是按层存储的，用字典可以把 “层的名字” 和 “对应的参数张量” 对应起来。比如之前的 MLP 模型，net.state_dict()返回的就是一个字典：

```python
# 假设已经训练好MLP模型net

print(net.state_dict())

# 输出结果（简化版）：

# {

# 'hidden.weight': tensor(...), # hidden层的权重参数

# 'hidden.bias': tensor(...), # hidden层的偏置参数

# 'output.weight': tensor(...), # output层的权重参数

# 'output.bias': tensor(...) # output层的偏置参数

# }
```

这个字典把每一层的参数都标得清清楚楚，后续想单独修改某一层的参数（比如只更新 hidden 层的权重），直接按 “层名” 找就行，不用遍历所有参数。

### 3. 传数据：给函数 “精准传参”，减少错误

在写深度学习代码时，经常需要给函数传多个数据（比如模型、优化器、数据）。用字典传参，函数可以按 “键” 取需要的部分，不用管参数的顺序。比如一个训练函数：

```python
# 定义训练函数，从字典里取需要的参数

def train(model_dict, data_dict):

# 按键取模型和优化器

model = model_dict["model"]

optimizer = model_dict["optimizer"]

# 按键取训练数据

train_x = data_dict["train_x"]

train_y = data_dict["train_y"]

# 后续训练逻辑...

# 准备模型相关的字典

model_dict = {

"model": net, # 模型

"optimizer": torch.optim.SGD(net.parameters(), lr=0.01) # 优化器

}

# 准备数据相关的字典（之前定义的data_dict）

# 调用函数时，直接传两个字典，不用记顺序

train(model_dict, data_dict)
```

如果不用字典，传参时要严格按 “模型、优化器、训练特征、训练标签、测试特征、测试标签” 的顺序写，少一个或顺序错了就会报错；用字典传参，函数要啥就按键取，灵活又不容易错。

## 四、常见问题：字典的 “坑” 和注意事项

### 1. 键必须唯一：不能有两个一样的标签

就像现实中不能有两个 “身份证袋”，字典里也不能有重复的键。如果重复写，后面的会覆盖前面的：

```python
# 重复的键“train_x”，后面的会覆盖前面的

bad_dict = {

"train_x": torch.arange(4),

"train_x": torch.arange(5, 9) # 这个会覆盖前面的“train_x”

}

print(bad_dict["train_x"]) # 输出：tensor([5, 6, 7, 8])
```

### 2. 键的类型有限制：不能用 “列表” 当键

字典的键必须是 “不可变” 的类型（比如字符串、数字、[[元组]]），不能用 “[[列表]]”（可变类型）当键。比如下面这样会报错：

```python
# 错误：用列表当键

bad_dict = {

["train", "x"]: torch.arange(4) # 列表是可变的，不能当键

}

# 正确：用元组（不可变）当键

good_dict = {

("train", "x"): torch.arange(4) # 元组不可变，可以当键

}
```

不过在深度学习中，我们几乎用 “字符串” 当键（比如 “train_x”“hidden.weight”），很少遇到这个问题。

### 3. 字典没有顺序：不用纠结键值对的排列

在 Python 3.7 之前，字典的键值对是 “无序” 的（打印时顺序可能和创建时不一样）；Python 3.7 之后变成了 “有序”，但我们在使用时**不用依赖顺序**—— 因为字典的核心是 “按键查值”，不是按位置查值。比如：

```python
# 错误：用列表当键

bad_dict = {

["train", "x"]: torch.arange(4) # 列表是可变的，不能当键

}

# 正确：用元组（不可变）当键

good_dict = {

("train", "x"): torch.arange(4) # 元组不可变，可以当键

}
```

## 五、一句话总结

代码里的 “字典”，就是**带标签的收纳盒**：用 “键”（标签）对应 “值”（数据），存的时候贴好标签，用的时候按标签找，不用记顺序、不怕混乱。在深度学习中，不管是存张量、存模型参数还是传数据，字典都能帮我们 “精准管理”，是提高代码效率的核心工具之一。

下次再看到torch.save(mydict, "file.pth")这样的代码，就知道：“哦，这是把带标签的数据装成一盒，存到文件里啦！”