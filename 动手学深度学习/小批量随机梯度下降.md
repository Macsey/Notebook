核心目标是解决梯度下降（全量数据）“数据低效” 与随机梯度下降（单样本）“计算低效” 的矛盾

| 算法类型 | 数据处理方式 | 优点 | 缺点 |
| :--- | :--- | :--- | :--- |
| **梯度下降（GD）** | 全量训练数据计算梯度 | 梯度估计准确，收敛稳定 | 数据量大时计算耗时，内存占用高 |
| **随机梯度下降（SGD）** | 单一样本计算梯度 | 迭代快，内存需求低 | 梯度波动大，收敛不稳定；框架调用开销大 |
| **小批量随机梯度下降（MBGD）** | 随机抽取小批量样本（如 10/100 个）计算梯度 | 1. 利用向量化提升计算效率<br>2. 梯度方差降低（标准差降至 $1/\sqrt{b}$）<br>3. 平衡收敛速度与计算成本 | 需手动选择合适批量大小，需适配硬件内存 |