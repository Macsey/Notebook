## 存在的问题
隐变量模型存在着长期信息保存和短期输入缺失的问题
## 9.2.1门控记忆元
长短期记忆网络引入了**记忆元**（有些文献认为记忆元是隐状态的一种特殊类型， 它们与**隐状态**具有相同的形状，其设计目的是用**记录附加的信息**。）
控制记忆元：
1. 输出门：从单元中输出条目
2. 输入门：决定何时将数据读入单元
3. 遗忘门：重置单元的内容
作用；决定**什么时候记忆或忽略隐状态中的输入**

### 输入门、遗忘门和输出门
![[Pasted image 20251209200928.png]]
假设有h个隐藏单元，批量大小为n，输入数为d
$$
\begin{split}\begin{aligned}
\mathbf{I}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xi} + \mathbf{H}_{t-1} \mathbf{W}_{hi} + \mathbf{b}_i),\\
\mathbf{F}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xf} + \mathbf{H}_{t-1} \mathbf{W}_{hf} + \mathbf{b}_f),\\
\mathbf{O}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xo} + \mathbf{H}_{t-1} \mathbf{W}_{ho} + \mathbf{b}_o),
\end{aligned}\end{split}
$$
输入门是$\mathbf{I}_t \in \mathbb{R}^{n \times h}$
遗忘门是$\mathbf{F}_t \in \mathbb{R}^{n \times h}$
输出门是$\mathbf{O}_t \in \mathbb{R}^{n \times h}$

### 候选神经元
![[Pasted image 20251209201510.png]]
$$\tilde{\mathbf{C}}_t = \text{tanh}(\mathbf{X}_t \mathbf{W}_{xc} + \mathbf{H}_{t-1} \mathbf{W}_{hc} + \mathbf{b}_c),$$
### 记忆元
输入门$\mathbf{I}_t$:控制采用多少来自$\tilde{\mathbf{C}}_t$的新数据，
遗忘门$\mathbf{F}_t$控制保留多少过去的记忆元$\mathbf{C}_{t-1} \in \mathbb{R}^{n \times h}$的内容
$$\mathbf{C}_t = \mathbf{F}_t \odot \mathbf{C}_{t-1} + \mathbf{I}_t \odot \tilde{\mathbf{C}}_t.$$
![[Pasted image 20251209201948.png]]

### 隐状态
$$\mathbf{H}_t = \mathbf{O}_t \odot \tanh(\mathbf{C}_t).$$
只要输出门接近1，我们就能够有效地将所有记忆信息传递给预测部分， 
输出门接近0，我们只保留记忆元内的所有信息，而不需要更新隐状态。