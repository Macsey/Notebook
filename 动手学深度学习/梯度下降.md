## 1.3 梯度下降 

### 1. 算法原理
**直觉**：把损失函数想象成一座山，我们在山上某一点。为了最快下山，我们应该沿着**当前坡度最陡峭的反方向**走一步。

**一维更新公式**：
$$x \leftarrow x - \eta f'(x)$$

其中 $\eta$ (eta) 是**学习率 (Learning Rate)**，决定了步子迈多大。

### 2. 多维梯度下降

- **公式**：
$$x \leftarrow x - \eta \nabla f(x)$$
$\nabla f(x)$ 是梯度向量，指向函数值增加最快的方向，所以我们要减去它。


### 3. 学习率的重要性

- $\eta$ **太小**：步子太碎，走到天黑也下不了山（收敛极慢）。
    
- $\eta$ **太大**：步子太大，直接跨过了山谷跑到对面的山腰，甚至越跑越高（震荡、发散）。