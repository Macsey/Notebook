要理解 “多层感知机的从零开始实现”，我们可以把它类比成 “自己动手搭一个简单的图像识别小机器人”—— 这个机器人能看懂 Fashion-MNIST 数据集里的图片（比如 T 恤、裤子、鞋子），并判断图片属于哪一类。下面用 “搭机器人” 的逻辑，一步步拆解每一步的作用和原理，全程不涉及复杂公式。

### 先明确核心目标：让 “机器人” 学会认衣服

我们的 “机器人” 要解决的问题很具体：给一张 28×28 像素的黑白衣服图片（比如一件 T 恤），它能输出 “这是 T 恤”“这是裤子” 等 10 种结果中的正确答案。

要实现这个目标，我们需要做 5 件事：

1. 准备 “原材料”（加载数据，让机器人有图可看）；

2. 搭 “机器人的大脑”（初始化模型参数，相当于给大脑装基础电路）；

3. 装 “信号转换器”（激活函数，让大脑能处理复杂逻辑）；

4. 定 “判断规则”（模型结构，让大脑知道怎么从图片到答案）；

5. 教 “机器人纠错”（训练过程，让它越认越准）。

### 第一步：准备 “原材料”—— 加载数据

就像教小孩认东西需要先准备一堆图片一样，我们首先要给机器人 “喂” 训练数据（Fashion-MNIST）。

- **数据是什么样的？**

总共 7 万张图片：6 万张 “训练图”（用来教机器人学），1 万张 “测试图”（用来考机器人学得怎么样）。每张图是 28×28 像素的黑白图（比如一张 T 恤图，像素亮的地方是衣服，暗的地方是背景），对应 10 个类别（T 恤、裤子、连衣裙、鞋子等）。

- **代码里做了什么？**

代码中train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=256)的作用，相当于 “每次给机器人递 256 张图”（batch_size=256）。为什么不一次递完？因为一次递太多，机器人 “记不住”（电脑内存不够）；一次递太少，学得太慢。分批次递，效率最高。

### 第二步：搭 “机器人的大脑”—— 初始化模型参数

“大脑” 是机器人的核心，它的本质是 “一堆能调整的数字”（叫 “参数”），这些数字决定了机器人怎么 “思考”。我们的大脑分两层（所以叫 “多层” 感知机）：

- **第一层（隐藏层）**：负责 “看懂图片细节”（比如 T 恤的领口形状、裤子的裤腿长度）；

- **第二层（输出层）**：负责 “汇总细节，给出答案”（比如把 “领口 + 短袖” 的细节汇总，判断是 T 恤）。

要搭这两层，需要准备 4 个关键 “零件”（参数）：

|   |   |   |
|---|---|---|
|零件名称|作用（类比）|具体例子|
|W1（第一层权重）|把图片像素 “翻译” 成细节信号（比如 “像素 1 亮 = 可能是领口”）|一个 784×256 的数字表格（784 是 28×28 像素的总个数，256 是 “细节信号的数量”，可以理解为机器人一次能关注 256 个细节）|
|b1（第一层偏置）|给细节信号 “调灵敏度”（比如让 “领口信号” 更敏感，避免漏看）|256 个数字（对应 256 个细节信号，每个信号配一个 “灵敏度调节器”）|
|W2（第二层权重）|把 “细节信号” 汇总成 “类别答案”（比如 “领口 + 短袖”→T 恤）|一个 256×10 的数字表格（256 对应第一层的细节信号，10 对应 10 个衣服类别）|
|b2（第二层偏置）|给类别答案 “调可信度”（比如让 “T 恤答案” 的可信度更高，避免误判）|10 个数字（对应 10 个类别，每个类别配一个 “可信度调节器”）|

- **为什么参数要 “随机初始化”？**

就像给小孩一张白纸，让他自己画，而不是直接画好给他 —— 如果一开始就固定参数，机器人会 “先入为主”，学不会新东西。代码里用 “正态分布随机数（scale=0.01）”，是为了让初始参数都很小，避免一开始就 “走极端”（比如认定某张图一定是裤子）。

- **“attach_grad ()” 是干嘛的？**

相当于给每个参数装一个 “纠错记录仪”—— 后面训练时，机器人会根据 “认错的程度”，通过这个记录仪调整参数（比如这次把 T 恤认错成衬衫，记录仪会记下来：下次要调整 “领口信号” 的权重）。

### 第三步：装 “信号转换器”—— 激活函数（ReLU）

如果只靠两层线性计算（比如 “像素 × 权重 + 偏置”），机器人的大脑是 “一根筋”—— 只能处理简单的线性关系（比如 “像素越亮，越可能是白色 T 恤”），但实际图片的逻辑是复杂的（比如 “领口亮 + 袖口亮，才是 T 恤”）。

这时候就需要 “激活函数”，相当于给大脑装一个 “信号过滤器”：只让 “有用的信号” 通过，“没用的信号” 关掉。我们用的是最简单的 ReLU 函数，它的逻辑超简单：

**“如果信号值大于 0，就保留这个信号；如果小于等于 0，就把它变成 0（相当于关掉）”**

比如：

- 第一层计算出一个 “领口信号值 = 3”（有用）→ ReLU 保留 3；

- 计算出一个 “帽子信号值 =-2”（这张图是 T 恤，帽子信号没用）→ ReLU 把它变成 0，避免干扰判断。

没有 ReLU 的话，机器人可能会把 “帽子信号” 和 “领口信号” 混在一起，越学越乱。

### 第四步：定 “判断规则”—— 模型结构（net 函数）

模型结构就是 “机器人处理图片的步骤”，代码里的net(X)函数定义了这个步骤，总共两步：

#### 步骤 1：把图片 “压平”—— 从 2D 图变成 1D 向量

图片是 28×28 的 “二维格子”（比如第 1 行第 1 列是一个像素，第 1 行第 2 列是另一个像素），但机器人的大脑（两层参数）只能处理 “一维的数字列表”。所以需要用reshape((-1, 784))把图片 “压平”：

- 28×28=784：把每个像素按顺序排成一个长列表（比如第 1 行的 28 个像素→第 2 行的 28 个像素→…→第 28 行的 28 个像素）；

- -1：不用手动算有多少张图，让电脑自己判断（比如一次递 256 张图，就会自动变成 256 个 784 长度的列表）。

比如一张 T 恤图，压平后就是一个 784 个数字的列表，每个数字代表一个像素的亮度（0 = 黑，255 = 白）。

#### 步骤 2：让 “压平的图片” 经过大脑，输出答案

压平后的图片（784 个数字）会按以下流程计算，最终输出 10 个数字（对应 10 个类别的 “得分”）：

1. 第一层计算（处理细节）：

压平的图片 × W1（784×256） + b1（256 个数字）→ 得到 256 个 “细节信号”（比如 “领口信号 = 3”“袖口信号 = 2”“裤腿信号 = 0”）；

再经过 ReLU 激活函数→ 过滤掉没用的信号（比如 “裤腿信号 = 0” 保留 0，“领口信号 = 3” 保留 3），得到 “有用的细节信号”。

2. 第二层计算（输出答案）：

有用的细节信号 × W2（256×10） + b2（10 个数字）→ 得到 10 个 “类别得分”（比如 “T 恤得分 = 8”“裤子得分 = 2”“鞋子得分 = 1”）。

最后，得分最高的类别，就是机器人的 “判断结果”（比如得分 8 的 T 恤，就是它认为的答案）。

### 第五步：教 “机器人纠错”—— 训练过程

一开始，机器人的参数是随机的，肯定会认错（比如把裤子认成裙子）。训练的目的就是 “让它慢慢改对”，核心逻辑是 “错得越狠，改得越猛”。

#### 1. 定 “纠错标准”—— 损失函数

怎么判断机器人 “错得有多狠”？需要一个 “损失函数”（相当于 “扣分规则”）：

- 如果机器人判断对了（比如把 T 恤认成 T 恤），“损失值” 很小（扣分少）；

- 如果判断错了（比如把 T 恤认成鞋子），“损失值” 很大（扣分多）。

代码里用的 “交叉熵损失”，就是专门干这个的 —— 它会重点惩罚 “明明错了还很自信” 的情况（比如机器人把 T 恤认成鞋子，还给出很高的 “鞋子得分”，就会扣很多分）。

#### 2. 教 “怎么改错”—— 梯度下降（SGD）

知道错了，怎么改参数？用 “梯度下降”，类比成 “下山找最低点”：

- “损失值” 相当于 “山的高度”：山顶是 “全错”，山脚是 “全对”；

- “梯度” 相当于 “下山的方向”：告诉机器人 “往哪个方向调参数，能让损失值变小（下山）”；

- “学习率（lr=0.1）” 相当于 “每步走多大”：步子太大容易踩空（参数调过了，从一个错变成另一个错），步子太小走得慢（训练很久还学不会），0.1 是一个 “兼顾速度和安全” 的步长。

代码里的d2l.train_ch3或SGD优化器，就是自动做这件事：

1. 用训练图让机器人预测，算损失值（看扣多少分）；

2. 算 “梯度”（确定改参数的方向）；

3. 按 “学习率” 调参数（往山下走一步）；

4. 重复 1-3 步，直到 6 万张训练图都过一遍（这叫 “1 个 epoch”），总共重复 10 次（num_epochs=10）。

#### 3. 考 “机器人学得怎么样”—— 测试过程

每训练一段时间，就用 1 万张 “测试图” 考机器人：不给它正确答案，让它自己判断，然后统计 “正确率”。如果正确率越来越高，说明机器人真的学会了。

代码最后d2l.predict_ch3会展示几张测试图的预测结果，比如左边是原图，右边是机器人的判断，能直观看到它学得好不好。

### 最后总结：多层感知机到底是什么？

其实就是一个 “分层处理信息的数学模型”：

- 输入层（图片像素）：接收原始信息；

- 隐藏层（处理细节）：提炼有用的中间信息；

- 输出层（类别得分）：给出最终答案；

- 激活函数：让模型能处理复杂逻辑；

- 训练过程：通过 “犯错 - 改错”，慢慢优化参数，最终学会认图。

从零开始实现的意义，就是让我们看清 “每个零件的作用”—— 如果直接用现成的框架（比如 PyTorch 的nn.Sequential），可能会觉得 “模型是黑盒子”，但自己搭一遍，就知道 “机器人的大脑是怎么工作的” 了。

### 小练习（帮你加深理解）

1. 改 “隐藏层数量（num_hiddens）”：比如把 256 改成 128 或 512，看看正确率会不会变？（提示：隐藏层太少，细节抓不全；太多，机器人会 “想太多”，记混训练图）；

2. 加一层隐藏层：比如再加一个 W3、b3，看看会不会更准？（提示：层数多了，训练时间会变长，也可能 “学杂了”）；

3. 改 “学习率”：比如把 0.1 改成 0.01 或 1，看看训练速度和正确率有什么变化？（提示：学习率太小，学得慢；太大，容易 “学飞”，正确率忽高忽低）。